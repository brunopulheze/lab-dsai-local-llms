![logo_ironhack_blue 7](https://user-images.githubusercontent.com/23629340/40541063-a07a0a8a-601a-11e8-91b5-2f13e4e6b441.png)

# LAB | Installing and Running a Local Large Language Model (LLM)

## Learning Goals

After completing this exercise, you will be able to:

- Research and select a local Large Language Model (LLM) to install on your device
- Install and run the chosen LLM using a local interface
- Practice working with offline AI models for natural language processing tasks
- Develop skills in model exploration, installation, and usage beyond provided examples

## Requirements

- A computer with sufficient resources to run an LLM (usually at least 16GB RAM)
- Internet access to research and download model files and software
- Basic command line and software installation knowledge

## Getting Started

For this exercise, you will independently research a local LLM suitable for your device, find an installation method, and run it locally. It is highly recommended that you search for something different than what was already demonstrated in class. 

### Step A: Research & Select a Local LLM

- Use online resources to explore options for local LLMs compatible with your hardware and skill level.
- Consider factors like model size, supported platforms, interface types, and installation complexity.

### Step B: Install Your Chosen Model

- Follow the official installation guides or community documentation to download and set up your selected model on your device.
- This may involve installing dependencies, downloading model weights, and configuring software.

### Step C: Run and Interact with the Model

- Launch the model using the selected interface.
- Test the model with example prompts to understand its capabilities and limitations.
- Experiment with different prompts and observe responses generated entirely offline on your machine.

## Submission

After you have successfully installed and run your chosen local LLM and tested it with prompts, please do the following:

1. Take a screenshot showing:
   - The model running prompt or interface
   - Generated results/response from the model
2. Save the screenshot image file in your lab repository folder, for example, name it `llm_run_screenshot.png`.
3. Commit your work including the screenshot and push your branch to the remote.
4. Make a pull request and paste the PR link in the submission field in the Student Portal.

**Good luck!**